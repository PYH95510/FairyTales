{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "VECTOR_STORE_PATH = \"./vectorstore\"\n",
    "EMBEDDINGS_MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
    "EMBEDDINGS = HuggingFaceEmbeddings(model_name=EMBEDDINGS_MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #Clean and preprocess text.\n",
    "    #Remove hyphenation at line breaks\n",
    "    text = re.sub(r'-\\n','',text)\n",
    "    #Replace newlines within paragraphs with spaces\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "    #Remove multiple newlines\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    #Normalize whitespace\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore():\n",
    "    list_of_pdfs = [\n",
    "        \"pdfs/FairyTale1.pdf\",\n",
    "        \"pdfs/FairyTale2.pdf\"\n",
    "    ]\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    documents = []\n",
    "    for pdf in list_of_pdfs:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        pdf_documents = loader.load()\n",
    "        # Clean the text in each document\n",
    "        for doc in pdf_documents:\n",
    "            cleaned_content = clean_text(doc.page_content)\n",
    "            doc.page_content = cleaned_content\n",
    "            documents.append(doc)\n",
    "\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    vectorstore = FAISS.from_documents(chunked_documents, EMBEDDINGS)\n",
    "    vectorstore.save_local(VECTOR_STORE_PATH)\n",
    "\n",
    "    return vectorstore\n",
    "vectorstore = create_vectorstore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorstore():\n",
    "    if os.path.exists(VECTOR_STORE_PATH):\n",
    "        vectorstore = FAISS.load_local(VECTOR_STORE_PATH, EMBEDDINGS)\n",
    "    else:\n",
    "        vectorstore = create_vectorstore()\n",
    "    return vectorstore\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " 이 이야기의 주제는 복수와 그에 대한 결과입니다.蒙特克리스토 백작은 자신을 배신한 사람들에게 정의를 실현하기 위해 계획을 세웠지만, 결국 자신이 외롭고 슬플 것이라는 사실을 깨달았습니다.\n",
      "\n",
      "Sources:\n",
      "{'source': 'pdfs/FairyTale1.pdf', 'page': 9}\n",
      "{'source': 'pdfs/FairyTale1.pdf', 'page': 8}\n",
      "{'source': 'pdfs/FairyTale2.pdf', 'page': 35}\n",
      "{'source': 'pdfs/FairyTale1.pdf', 'page': 53}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    query = \"단테 신곡 동화 작성해주세요\"\n",
    "    response = rag_chain_with_source.invoke(query)\n",
    "\n",
    "    print(\"Answer:\\n\", response[\"answer\"] + \"\\n\")\n",
    "    print(\"Sources:\")\n",
    "    sources = [doc.metadata for doc in response[\"context\"]]\n",
    "    for source in sources:\n",
    "        print(source)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
